\contentsline {section}{\numberline {1}Computer Architecture}{5}{section.1}%
\contentsline {subsection}{\numberline {1.1}How is Data represented?}{5}{subsection.1.1}%
\contentsline {section}{\numberline {2}Introduction}{5}{section.2}%
\contentsline {section}{\numberline {3}Classification of Architectures - Flynn's Taxonomy}{7}{section.3}%
\contentsline {subsection}{\numberline {3.1}SIMD - Single Instruction Multiple Data}{7}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}MISD - Multiple Instruction Single Data}{9}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}MIMD - Mutliple Instruction Multiple Data}{9}{subsection.3.3}%
\contentsline {section}{\numberline {4}Classification based on Memory}{10}{section.4}%
\contentsline {subsection}{\numberline {4.1}Shared Memory}{10}{subsection.4.1}%
\contentsline {subsubsection}{\numberline {4.1.1}Uniform Memory Access (UMA)}{11}{subsubsection.4.1.1}%
\contentsline {subsubsection}{\numberline {4.1.2}Non-Uniform Memory Access (NUMA)}{12}{subsubsection.4.1.2}%
\contentsline {subsection}{\numberline {4.2}Distributed Memory Architecture}{13}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Shared Memory Architectures: Cache Coherence}{14}{subsection.4.3}%
\contentsline {subsubsection}{\numberline {4.3.1}State Transition Diagram}{15}{subsubsection.4.3.1}%
\contentsline {subsection}{\numberline {4.4}Implementation of Cache Coherence Protocols}{16}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Snooping Protocol}{16}{subsubsection.4.4.1}%
\contentsline {subsubsection}{\numberline {4.4.2}Directory Based Protocol}{16}{subsubsection.4.4.2}%
\contentsline {subsection}{\numberline {4.5}False Sharing}{17}{subsection.4.5}%
\contentsline {section}{\numberline {5}Interconnection networks for a Parallel Computer}{19}{section.5}%
\contentsline {subsection}{\numberline {5.1}Network Topology}{20}{subsection.5.1}%
\contentsline {subsubsection}{\numberline {5.1.1}Bus-based networks}{20}{subsubsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.2}Cross-bar Networks}{21}{subsubsection.5.1.2}%
\contentsline {subsubsection}{\numberline {5.1.3}Multistage Network}{22}{subsubsection.5.1.3}%
\contentsline {subsubsection}{\numberline {5.1.4}Completely Connected Networks}{27}{subsubsection.5.1.4}%
\contentsline {subsubsection}{\numberline {5.1.5}Star Connected Network/Star Topology}{28}{subsubsection.5.1.5}%
\contentsline {subsubsection}{\numberline {5.1.6}Linear Arrays, Meshes and k-d Meshes}{29}{subsubsection.5.1.6}%
\contentsline {subsubsection}{\numberline {5.1.7}Tree Based Networks}{31}{subsubsection.5.1.7}%
\contentsline {subsection}{\numberline {5.2}Evaluating Static Networks}{32}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Diameter}{32}{subsubsection.5.2.1}%
\contentsline {subsubsection}{\numberline {5.2.2}Connectivity}{33}{subsubsection.5.2.2}%
\contentsline {subsubsection}{\numberline {5.2.3}Bisection Width and Bisection Bandwidth}{33}{subsubsection.5.2.3}%
\contentsline {subsubsection}{\numberline {5.2.4}Cost}{34}{subsubsection.5.2.4}%
\contentsline {section}{\numberline {6}Graphical Processing Units}{35}{section.6}%
\contentsline {subsection}{\numberline {6.1}GPU Architecture}{36}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}CUDA Memory Spaces}{38}{subsection.6.2}%
\contentsline {section}{\numberline {7}Parallelization Principles}{41}{section.7}%
\contentsline {subsection}{\numberline {7.1}Evaluation of Parallel Programs}{41}{subsection.7.1}%
\contentsline {section}{\numberline {8}Parallel Programming Classification and Steps}{46}{section.8}%
\contentsline {subsection}{\numberline {8.1}Parallel Program Models}{46}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Programming Paradigms}{46}{subsection.8.2}%
\contentsline {subsection}{\numberline {8.3}Parallelizing a Program}{46}{subsection.8.3}%
\contentsline {subsection}{\numberline {8.4}Data Parallelism and Data Decomposition}{47}{subsection.8.4}%
\contentsline {subsection}{\numberline {8.5}Data Distributions}{48}{subsection.8.5}%
\contentsline {subsection}{\numberline {8.6}Task Parallelism}{49}{subsection.8.6}%
\contentsline {subsection}{\numberline {8.7}Orchestration}{50}{subsection.8.7}%
\contentsline {subsubsection}{\numberline {8.7.1}Maximizing data locality: }{50}{subsubsection.8.7.1}%
\contentsline {subsubsection}{\numberline {8.7.2}Minimizing contention and hotspots: }{51}{subsubsection.8.7.2}%
\contentsline {subsubsection}{\numberline {8.7.3}Overlapping computations with interactions}{52}{subsubsection.8.7.3}%
\contentsline {subsubsection}{\numberline {8.7.4}Replicating data or computations }{53}{subsubsection.8.7.4}%
\contentsline {subsection}{\numberline {8.8}Mapping}{53}{subsection.8.8}%
\contentsline {subsection}{\numberline {8.9}Example}{55}{subsection.8.9}%
\contentsline {subsection}{\numberline {8.10}Notes on Message Passing Version}{68}{subsection.8.10}%
\contentsline {subsection}{\numberline {8.11}Send and Receive Alternatives}{69}{subsection.8.11}%
\contentsline {subsection}{\numberline {8.12}Summary}{70}{subsection.8.12}%
\contentsline {section}{\numberline {9}Shared Memory Parallelism - OpenMP}{71}{section.9}%
\contentsline {subsection}{\numberline {9.1}Introduction}{71}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}Fork-Join Model}{71}{subsection.9.2}%
\contentsline {subsection}{\numberline {9.3}Parallel Construct}{73}{subsection.9.3}%
\contentsline {subsection}{\numberline {9.4}Work sharing construct}{75}{subsection.9.4}%
\contentsline {subsubsection}{\numberline {9.4.1}for-loop}{75}{subsubsection.9.4.1}%
\contentsline {subsubsection}{\numberline {9.4.2}Coarse Level parallelism - Sections and Tasks}{77}{subsubsection.9.4.2}%
\contentsline {subsection}{\numberline {9.5}Synchronization Directives}{79}{subsection.9.5}%
\contentsline {subsection}{\numberline {9.6}Data Scope Attribute Clauses}{82}{subsection.9.6}%
\contentsline {subsubsection}{\numberline {9.6.1}threadprivate}{83}{subsubsection.9.6.1}%
\contentsline {subsubsection}{\numberline {9.6.2}default-example}{84}{subsubsection.9.6.2}%
\contentsline {subsection}{\numberline {9.7}Library Routines (API)}{85}{subsection.9.7}%
\contentsline {subsection}{\numberline {9.8}Locks}{86}{subsection.9.8}%
\contentsline {subsection}{\numberline {9.9}Example 1: Jacobi Solver}{88}{subsection.9.9}%
\contentsline {subsection}{\numberline {9.10}Breadth First Search (BFS) Algorithm}{89}{subsection.9.10}%
\contentsline {subsubsection}{\numberline {9.10.1}Version 1 (Nested Parallelism)}{89}{subsubsection.9.10.1}%
\contentsline {subsubsection}{\numberline {9.10.2}Version 2 (Task constructs)}{91}{subsubsection.9.10.2}%
\contentsline {section}{\numberline {10}Message Passing Interface - MPI}{92}{section.10}%
\contentsline {subsection}{\numberline {10.1}MPI Intrdocution}{92}{subsection.10.1}%
\contentsline {subsection}{\numberline {10.2}Communication Primitives}{93}{subsection.10.2}%
\contentsline {subsubsection}{\numberline {10.2.1}Point-Point Communications}{93}{subsubsection.10.2.1}%
\contentsline {subsubsection}{\numberline {10.2.2}EXAMPLE 1: Finding maximum using 2 processes}{96}{subsubsection.10.2.2}%
\contentsline {subsection}{\numberline {10.3}Buffering and Safety}{98}{subsection.10.3}%
\contentsline {subsubsection}{\numberline {10.3.1}Blocking Communications}{98}{subsubsection.10.3.1}%
\contentsline {subsubsection}{\numberline {10.3.2}Non-Blocking Communications}{100}{subsubsection.10.3.2}%
\contentsline {subsection}{\numberline {10.4}Example: Finding a Particular element in an Array}{102}{subsection.10.4}%
\contentsline {subsection}{\numberline {10.5}Communication Modes}{104}{subsection.10.5}%
